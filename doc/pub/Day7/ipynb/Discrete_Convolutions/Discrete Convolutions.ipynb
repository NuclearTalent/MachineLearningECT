{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Welcome to Convolutional Neural Networks!\n",
    "\n",
    "---\n",
    "\n",
    "ECT* TALENT Summer School 2020\n",
    "\n",
    "*Dr. Michelle P. Kuchera*\n",
    "\n",
    "*Davidson College*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<!-- I read it's useful to add a bit of personal information when teaching virtual classes -->\n",
    "\n",
    "## Research interests:\n",
    "\n",
    " - ### Machine learning to address challenges in nuclear physics (and high-energy physics)\n",
    " - FRIB experiments\n",
    " - Jefferson Lab experiments\n",
    " - Jefferson Lab Theory Center\n",
    " \n",
    " -----\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks: Convoution Operations\n",
    "\n",
    "<!-- 1943 -- McCullough and Pitts computational model of a neuron -->\n",
    "The convolutional neural network architecture was first described by Kunihiko Fukushima in 1980 (!). \n",
    "\n",
    "*Discrete convolutions* are matrix operations that can, amongst other things, be used to apply *filters* to images. Convolutions (continuous) we first published in 1754 (!!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    " - In this session, we will be looking at *predefined* filters for images to gain an intuition or understanding as to how the convolutional filters look. \n",
    " - In the next session, we will add them into a neural network architecture to create convolutional neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Given an image `A` and a filter `h` with dimensions of $(2\\omega+1) \\times (2\\omega+1)$, the discrete convolution operation is given by the following mathematics:\n",
    "\n",
    "$$C=x\\circledast h$$\n",
    "\n",
    "where\n",
    "\n",
    "$$C[m,n] = 􏰅 \\sum_{j=-\\omega}^{\\omega}\\sum_{i=-\\omega}^{\\omega} h[i+\\omega,j+\\omega]* A[m+i,n+j]$$\n",
    "\n",
    "Or, graphically:\n",
    "\n",
    "![conv](conv.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Details\n",
    "\n",
    " * The filter slides across the image and down the image.\n",
    " * *Stride* is how many elements (pixels) you slide the filter by after each operation. This affects the dimensionality of the output of each image.\n",
    " * There are choices to be made at the edges.\n",
    "    - for a stride of $1$ and a filter dimension of $3$, as shown here, the outer elements can not be computed as described.\n",
    "    - one solution is *padding*, or adding zeros around the outside of the image so that the output can maintain the same shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, I will demonstrate the application of discrete convolutions of known filters on an image.\n",
    "\n",
    "First, we `import` our necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, let's define a function to execute the above operation for any given 2-dimensional image and filter matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def conv2d(img, filt, stride):\n",
    "\n",
    "    n_rows = len(img)\n",
    "    n_cols = len(img[0])\n",
    "    filt_w = len(filt)\n",
    "    filt_h = len(filt[0])\n",
    "    \n",
    "    #store our filtered image\n",
    "    new_img = np.zeros((n_rows//stride+1,n_cols//stride+1))\n",
    "  \n",
    "    # print(n_rows,n_cols,filt_w,filt_h) # uncomment for debugging\n",
    "\n",
    "\n",
    "    for i in range(filt_w//2,n_rows-filt_w//2, stride):\n",
    "        for j in range(filt_h//2,n_cols-filt_h//2, stride):\n",
    "           \n",
    "            new_img[i//stride,j//stride] = np.sum(img[i-filt_w//2:i+filt_w//2+1,j-filt_h//2:j+filt_h//2+1]*filt)\n",
    "           \n",
    "    return new_img\n",
    "                                                                                         \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will first generate a simple synthetic image to which we will apply filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test_img = np.zeros((128,128)) # make an image 128x128 pixels, start by making it entirely black\n",
    "test_img[30,:] = 255 # add a white row\n",
    "test_img[:,40] = 255 # add a white column\n",
    "\n",
    "# add two diagonal lines\n",
    "for i in range(len(test_img)):\n",
    "    for j in range(len(test_img[i])):\n",
    "        if i == j or i == j+10:\n",
    "            test_img[i,j] = 255\n",
    "plt.imshow(test_img, cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's also investigate the inverse of this image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# creating the inverse of test_img\n",
    "test_img2 = 255 - test_img\n",
    "plt.imshow(test_img2, cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We will create three filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "size = 3 # number of rows and columns for filters\n",
    "\n",
    "# modify all values\n",
    "filter1 = np.zeros((size,size))\n",
    "filter1[:,:] = 0.5\n",
    "\n",
    "# all values -1 except horizonal stripe in center\n",
    "filter2 = np.zeros((size,size))\n",
    "filter2[:,:] = -1\n",
    "filter2[size//2,:] = 2\n",
    "\n",
    "# all values -1 except vertical stripe in center\n",
    "filter3 = np.zeros((size,size))\n",
    "filter3[:,:] = -1\n",
    "filter3[:,size//2] = 2\n",
    "\n",
    "print(filter1,filter2,filter3, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### And now we call our function `conv2d` with our test images and our first filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_image = conv2d(test_img, filter3,1)\n",
    "plt.imshow(filtered_image, cmap=\"gray\")   \n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "filtered_image2 = conv2d(test_img2, filter3,1)\n",
    "plt.imshow(filtered_image2, cmap=\"gray\")   \n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In practice, you do not have to code the 2d convolutions (or you can do it in a more vectorized way using the full power of `numpy`).\n",
    "\n",
    "Let's look at the 2d convolutional method from `scipy`. The `mode=\"same\"` argument indicates that our output matrix should match our input matrix.\n",
    "\n",
    "\n",
    "\n",
    "Note that he following import statement was executed at the beginning of this notebook:\n",
    "\n",
    "```python\n",
    "from scipy import signal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "spy_image = signal.      (test_img, filter3, mode=\"same\")\n",
    "spy_image2 = signal.convolve2d(test_img2, filter3, mode=\"same\")\n",
    "\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,sharex=True, sharey=True, figsize = (8,8))\n",
    "\n",
    "ax1.imshow(spy_image, cmap=\"gray\")\n",
    "#plt.colorbar()\n",
    "#plt.show()\n",
    "\n",
    "ax2.imshow(spy_image2, cmap=\"gray\")\n",
    "#plt.colorbar()\n",
    "#fig.add_subplot(f1)\n",
    "#plt.show()\n",
    "ax3.imshow(filtered_image, cmap=\"gray\")\n",
    "ax4.imshow(filtered_image2, cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Filter 1 is a *blurring* filter. \n",
    "\n",
    "It takes an \"average\" of all of the pixels in the region of the filter, all with the same weight.\n",
    "\n",
    "#### Let's go back and investigate the other filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Filter 1 is a *blurring* filter. \n",
    "\n",
    "It takes an \"average\" of all of the pixels in the region of the filter, all with the same weight.\n",
    "\n",
    "## Filter 2 detects horizontal lines. \n",
    "\n",
    "It takes an \"average\" of all of the pixels in the region of the filter, all with the same weight.\n",
    "\n",
    "## Filter 3 detects vertical lines. \n",
    "\n",
    "It takes an \"average\" of all of the pixels in the region of the filter, all with the same weight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "residuals = spy_image-filtered_image\n",
    "plt.imshow(residuals)  \n",
    "plt.title(\"Residuals\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(residuals[len(filter1):-len(filter1),len(filter1[0]):-len(filter1[0])])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.hist(residuals[len(filter1):-len(filter1),len(filter1[0]):-len(filter1[0])].flatten())\n",
    "plt.show()\n",
    "print(\"number of non-zero residuals (removing with of filter all the away around the image):\", np.count_nonzero(residuals[len(filter1):-len(filter1),len(filter1[0]):-len(filter1[0])].flatten()))         \n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Let's try with a real photograph.\n",
    "\n",
    "Since we have only defined 2D convolutions for a 2D matrix, we cannot apply our function to color images, which have three channels: (red (R), green (G), blue (B)).\n",
    "\n",
    "Therefore, we make a gray scale image by averaging over the three <font color=\"red\">R<font color=\"green\">G<font color=\"blue\">B <font color=\"black\">channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "house = plt.imread(\"house_copy.jpg\", format=\"jpeg\")\n",
    "\n",
    "plt.imshow(house)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "bw_house = np.mean(house, axis=2)\n",
    "\n",
    "plt.imshow(bw_house, cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "spy_image = signal.convolve2d(bw_house, filter1, mode=\"same\")\n",
    "plt.imshow(spy_image, cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "spy_image = signal.convolve2d(bw_house, filter2, mode=\"same\")\n",
    "plt.imshow(spy_image, cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "spy_image = signal.convolve2d(bw_house, filter3, mode=\"same\")\n",
    "plt.imshow(spy_image, cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can look at the effects of modifying the *stride*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_conv = conv2d(bw_house,filter3,5)\n",
    "plt.imshow(my_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $N$-D convolutions\n",
    "\n",
    "The mathmatics of discrete convolutions are the same no matter the dimensionality. \n",
    "\n",
    "Let's first look at 1D convolutions:\n",
    "\n",
    "Given a 1-D data array `a` and a filter `h` with dimensions of $2\\omega \\times 2\\omega$, the discrete convolution operation is given by the following mathematics:\n",
    "\n",
    "$$c[n]=a[n]\\circledast h= 􏰅 \\sum_{i=-\\omega}^{\\omega} a[i+n]* h[i+\\omega]$$\n",
    "<!-- $$C[m,n]=x[m,n]\\circledast h= 􏰅 \\sum_{j=-\\omega}^{\\omega}\\sum_{i=-\\omega}^{\\omega} h[i+\\omega,j+\\omega]* A[m+i,n+j]$$-->\n",
    "\n",
    "\n",
    "\n",
    "Or, graphically:\n",
    "\n",
    "![conv](conv1d.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d(arr, filt, stride):\n",
    "\n",
    "    n = len(arr)\n",
    "    filt_w = len(filt)\n",
    "    \n",
    "    #store our filtered image\n",
    "    new_arr = np.zeros(n//stride+1)\n",
    "  \n",
    "    # print(n_rows,n_cols,filt_w,filt_h) # uncomment for debugging\n",
    "\n",
    "\n",
    "    for i in range(filt_w//2,n-filt_w//2, stride):  \n",
    "            new_arr[i//stride] = np.sum(arr[i-filt_w//2:i+filt_w//2+1]*filt)\n",
    "           \n",
    "    return new_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from random import random\n",
    "x = np.linspace(0,1,100)\n",
    "y = np.sin(15*x)+2*x**2 + np.random.rand(len(x))\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, we define our filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "size = 5\n",
    "f1 = np.zeros(size)\n",
    "f1[:] = 0.5\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And we convolve our image with our filter aand look at the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "new_array = conv1d(y,f1,1)\n",
    "plt.plot(new_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this is still a *blurring* filter, but we would perhaps think of it as a *smoothing* filter in the 2D case.\n",
    "\n",
    ":: I hope you can see that this simply extends to any dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
